COMPOSE_PROJECT_NAME=wrenai-multi-llm
PLATFORM=linux/amd64

PROJECT_DIR=.

# service ports
WREN_ENGINE_PORT=8080
WREN_ENGINE_SQL_PORT=7432
IBIS_SERVER_PORT=8000

# AI service ports for different LLMs
WREN_AI_SERVICE_PORT_OPENAI=5555
WREN_AI_SERVICE_PORT_GROQ=5556
WREN_AI_SERVICE_PORT_OLLAMA=5557

# UI ports for accessing different LLM interfaces
HOST_PORT_OPENAI=3001
HOST_PORT_GROQ=3002
HOST_PORT_OLLAMA=3003

# AI service forward ports (external access)
AI_SERVICE_FORWARD_PORT_OPENAI=5555
AI_SERVICE_FORWARD_PORT_GROQ=5556
AI_SERVICE_FORWARD_PORT_OLLAMA=5557

# ai service settings
QDRANT_HOST=qdrant
SHOULD_FORCE_DEPLOY=1

# vendor keys - add your API keys here
OPENAI_API_KEY=
GROQ_API_KEY=
# For Ollama, no API key needed

# version
WREN_PRODUCT_VERSION=0.25.0
WREN_ENGINE_VERSION=0.17.1
WREN_AI_SERVICE_VERSION=0.24.3
IBIS_SERVER_VERSION=0.17.1
WREN_UI_VERSION=0.30.0
WREN_BOOTSTRAP_VERSION=0.1.5

# user id (uuid v4)
USER_UUID=

# for other services
POSTHOG_API_KEY=phc_nhF32aj4xHXOZb0oqr2cn4Oy9uiWzz6CCP4KZmRq9aE
POSTHOG_HOST=https://app.posthog.com
TELEMETRY_ENABLED=true

# Generation models for telemetry/display
GENERATION_MODEL_OPENAI=gpt-4o-mini
GENERATION_MODEL_GROQ=llama-3.3-70b-specdec
GENERATION_MODEL_OLLAMA=phi4:14b

# LangFuse settings
LANGFUSE_SECRET_KEY=
LANGFUSE_PUBLIC_KEY=

# Wren UI
EXPERIMENTAL_ENGINE_RUST_VERSION=false

# Wren Engine
LOCAL_STORAGE=.
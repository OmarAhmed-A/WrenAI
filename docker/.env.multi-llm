COMPOSE_PROJECT_NAME=wrenai-multi-llm
PLATFORM=linux/amd64

PROJECT_DIR=.

# service ports
WREN_ENGINE_PORT=8080
WREN_ENGINE_SQL_PORT=7432
IBIS_SERVER_PORT=8000

# AI service ports for different LLMs
WREN_AI_SERVICE_PORT_GPT_4_1_MINI=5555
WREN_AI_SERVICE_PORT_GPT_O4_MINI=5556
WREN_AI_SERVICE_PORT_GPT_O3=5557
WREN_AI_SERVICE_PORT_CLAUDE_SONNET_4=5558

# UI ports for accessing different LLM interfaces
HOST_PORT_GPT_4_1_MINI=1041
HOST_PORT_GPT_O4_MINI=1004
HOST_PORT_GPT_O3=1003
HOST_PORT_CLAUDE_SONNET_4=2004

# AI service forward ports (external access)
AI_SERVICE_FORWARD_PORT_GPT_4_1_MINI=5555
AI_SERVICE_FORWARD_PORT_GPT_O4_MINI=5556
AI_SERVICE_FORWARD_PORT_GPT_O3=5557
AI_SERVICE_FORWARD_PORT_CLAUDE_SONNET_4=5558

# ai service settings
QDRANT_HOST=qdrant
# SHOULD_FORCE_DEPLOY is not set for multi-LLM setup to avoid wren-ui dependency
# SHOULD_FORCE_DEPLOY=

# vendor keys - add your API keys here
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# version
WREN_PRODUCT_VERSION=0.25.0
WREN_ENGINE_VERSION=0.17.1
WREN_AI_SERVICE_VERSION=0.24.3
IBIS_SERVER_VERSION=0.17.1
WREN_UI_VERSION=0.30.0
WREN_BOOTSTRAP_VERSION=0.1.5

# user id (uuid v4)
USER_UUID=

# for other services
POSTHOG_API_KEY=phc_nhF32aj4xHXOZb0oqr2cn4Oy9uiWzz6CCP4KZmRq9aE
POSTHOG_HOST=https://app.posthog.com
TELEMETRY_ENABLED=true

# Generation models for telemetry/display
GENERATION_MODEL_GPT_4_1_MINI=gpt-4.1-mini-2025-04-14
GENERATION_MODEL_GPT_O4_MINI=gpt-4.1-nano-2025-04-14
GENERATION_MODEL_GPT_O3=gpt-4.1-2025-04-14
GENERATION_MODEL_CLAUDE_SONNET_4=anthropic/claude-sonnet-4-20250514

# LangFuse settings
LANGFUSE_SECRET_KEY=
LANGFUSE_PUBLIC_KEY=

# Wren UI
EXPERIMENTAL_ENGINE_RUST_VERSION=false

# Wren Engine
LOCAL_STORAGE=.